{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00717488-997c-4efc-8ed1-6d62adf320d3",
   "metadata": {},
   "source": [
    "<center><font size=20> ECE 685D HW5</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153aadd-9617-40cb-ba9e-879ba030bc80",
   "metadata": {},
   "source": [
    "<font size=6>1 Problem 1: GAN (30 pts)<br><font size=5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867b4016-8d4d-420b-8435-71df66578c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Generate images with condition labels\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622a8fd0-bc59-4b0e-9abc-ee1d29718c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 30\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1e6acd-90ea-4b2c-ad01-18c3e1d8ace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 11808332.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 48069719.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 4722530.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 6698498.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Put your code here\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facc59ec-5439-41d1-bdc1-1652c598c372",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (902883267.py, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 51\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.G =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function should return batch of images.\"\"\"\n",
    "        \n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "        return\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function should return the logits.\"\"\"\n",
    "        \n",
    "        ##################################################\n",
    "        #                                                #\n",
    "        #            ---- YOUR CODE HERE ----            #\n",
    "        #                                                #\n",
    "        ##################################################\n",
    "        \n",
    "        return\n",
    "\n",
    "class DCGAN(object):\n",
    "    \n",
    "    def __init__(self, epochs, batch_size):\n",
    "        \n",
    "        ##### ---- YOUR CODE HERE ---- #####\n",
    "        self.G = \n",
    "        self.D = \n",
    "        self.loss = \n",
    "        ##### ----                ---- #####\n",
    "\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.number_of_images = 10\n",
    "        \n",
    "    def train(self, train_loader):\n",
    "        \n",
    "        disc_loss = []\n",
    "        genr_loss = []\n",
    "        \n",
    "        generator_iter = 0\n",
    "        \n",
    "        for epoch in trange(self.epochs):\n",
    "\n",
    "            for i, (images, _) in enumerate(train_loader):\n",
    "                \n",
    "                # Step 1: Train discriminator\n",
    "                z = torch.rand((self.batch_size, 100, 1, 1))\n",
    "                \n",
    "                real_labels = torch.ones(self.batch_size)\n",
    "                fake_labels = torch.zeros(self.batch_size)\n",
    "\n",
    "                images, z = images.to(device), z.to(device)\n",
    "                real_labels, fake_labels = real_labels.to(device), fake_labels.to(device)\n",
    "\n",
    "                # Compute the BCE Loss using real images\n",
    "                real_logits = self.D(images)\n",
    "                real_logits = torch.squeeze(real_logits)\n",
    "                d_loss_real = self.loss(real_logits, real_labels)\n",
    "\n",
    "                # Compute the BCE Loss using fake images\n",
    "                fake_images = self.G(z)\n",
    "                fake_logits = self.D(fake_images)\n",
    "                fake_logits = torch.squeeze(fake_logits)\n",
    "                d_loss_fake = self.loss(fake_logits, fake_labels)\n",
    "\n",
    "                # Optimize discriminator\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                self.D.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Step 2: Train Generator\n",
    "                z = torch.randn(self.batch_size, 100, 1, 1).to(device)\n",
    "                \n",
    "                fake_images = self.G(z)\n",
    "                fake_logits = self.D(fake_images)\n",
    "                fake_logits = torch.squeeze(fake_logits)\n",
    "                g_loss = self.loss(fake_logits, real_labels)\n",
    "\n",
    "                self.D.zero_grad()\n",
    "                self.G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "                generator_iter += 1\n",
    "\n",
    "                disc_loss.append(d_loss.item())\n",
    "                genr_loss.append(g_loss.item())\n",
    "\n",
    "        return disc_loss, genr_loss\n",
    "\n",
    "    def generate_img(self, z, number_of_images):\n",
    "        samples = self.G(z).data.cpu().numpy()[:number_of_images]\n",
    "        generated_images = []\n",
    "        for sample in samples:\n",
    "            generated_images.append(sample.reshape(28, 28))\n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1e891a-531f-4fbf-b296-2464458c24c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DCGAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDCGAN\u001b[49m(epochs, batch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DCGAN' is not defined"
     ]
    }
   ],
   "source": [
    "model = DCGAN(epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39aee68a-cdfb-4482-a4f9-574fc4727e5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m disc_loss, genr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mtrain(train_loader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "disc_loss, genr_loss = model.train(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2dd27e-39eb-4095-9ee4-ebfddab79845",
   "metadata": {},
   "source": [
    "<font size=6>2 Problem 2: n-gram with LSTM (40 pts)<br><font size=5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fc4df-61a1-4a67-82ff-c41d551c1aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11498ac1-50b2-43e1-8b3e-33dabfeacd56",
   "metadata": {},
   "source": [
    "<font size=6>3 Problem 3: Recurrent model for human activity prediction (30 pts)<br><font size=5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0ad6f-5b32-46fd-8b5c-5bec1c6a0eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE685D",
   "language": "python",
   "name": "ece685d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
