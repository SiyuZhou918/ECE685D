{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"!pip install medmnist","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:08.115156Z","iopub.execute_input":"2023-12-02T15:34:08.11622Z","iopub.status.idle":"2023-12-02T15:34:20.09407Z","shell.execute_reply.started":"2023-12-02T15:34:08.116185Z","shell.execute_reply":"2023-12-02T15:34:20.092861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport os\n\nimport medmnist\nfrom medmnist import INFO, Evaluator\n\n# Generate images with condition labels\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch import nn\nfrom torch.utils.data import Subset\nimport torch.optim as optim\n\nimport numpy as np\nimport pandas as pd","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-02T15:34:20.096805Z","iopub.execute_input":"2023-12-02T15:34:20.097679Z","iopub.status.idle":"2023-12-02T15:34:20.10817Z","shell.execute_reply.started":"2023-12-02T15:34:20.097639Z","shell.execute_reply":"2023-12-02T15:34:20.107193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:20.109289Z","iopub.execute_input":"2023-12-02T15:34:20.10967Z","iopub.status.idle":"2023-12-02T15:34:20.12473Z","shell.execute_reply.started":"2023-12-02T15:34:20.109634Z","shell.execute_reply":"2023-12-02T15:34:20.123772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation Function","metadata":{}},{"cell_type":"code","source":"class TransformsSimCLR:\n    \"\"\"\n    A stochastic data augmentation module that transforms any given data example randomly\n    resulting in two correlated views of the same example,\n    denoted x ̃i and x ̃j, which we consider as a positive pair.\n    \"\"\"\n\n    def __init__(self,size):\n        color_jitter = torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n        \n        self.transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.RandomResizedCrop(size=size),\n                torchvision.transforms.RandomHorizontalFlip(),\n                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n                torchvision.transforms.RandomGrayscale(p=0.2),\n                torchvision.transforms.ToTensor(),\n                transforms.Normalize(mean=[.5], std=[.5])\n            ]\n        )\n\n    def __call__(self, x):\n        return self.transform(x), self.transform(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:20.127281Z","iopub.execute_input":"2023-12-02T15:34:20.127582Z","iopub.status.idle":"2023-12-02T15:34:20.135494Z","shell.execute_reply.started":"2023-12-02T15:34:20.127557Z","shell.execute_reply":"2023-12-02T15:34:20.134639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20\nBATCH_SIZE = 128\nnum_epochs_finetune = 20","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:20.136562Z","iopub.execute_input":"2023-12-02T15:34:20.136808Z","iopub.status.idle":"2023-12-02T15:34:20.149987Z","shell.execute_reply.started":"2023-12-02T15:34:20.136786Z","shell.execute_reply":"2023-12-02T15:34:20.149219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"#load \n\n#data_flag = 'pneumoniamnist'\ndata_flag = 'pathmnist'\n#data_flag='bloodmnist'\n\n\ndownload = True\n\ninfo = INFO[data_flag]\ntask = info['task']\nn_channels = info['n_channels']\nn_classes = len(info['label'])\n\nDataClass = getattr(medmnist, info['python_class'])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:20.151139Z","iopub.execute_input":"2023-12-02T15:34:20.151407Z","iopub.status.idle":"2023-12-02T15:34:20.160665Z","shell.execute_reply.started":"2023-12-02T15:34:20.151383Z","shell.execute_reply":"2023-12-02T15:34:20.15974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocessing\n\ntrain_transform = TransformsSimCLR(size=(28,28))\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[.5], std=[.5])\n])\n\n# load the data\ntrain_dataset = DataClass(split='train', transform=train_transform, download=download)\ntest_dataset = DataClass(split='test', transform=test_transform, download=download)\n\nfinetuning_set = DataClass(split='train', transform=test_transform, download=download)\n\n\n# encapsulate data into dataloader form\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:20.161941Z","iopub.execute_input":"2023-12-02T15:34:20.16229Z","iopub.status.idle":"2023-12-02T15:34:24.091587Z","shell.execute_reply.started":"2023-12-02T15:34:20.162257Z","shell.execute_reply":"2023-12-02T15:34:24.090485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(train_loader)\n(sample_1, sample_2), sample_label = next(dataiter)\nsample_1.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.093531Z","iopub.execute_input":"2023-12-02T15:34:24.093934Z","iopub.status.idle":"2023-12-02T15:34:24.210728Z","shell.execute_reply.started":"2023-12-02T15:34:24.093896Z","shell.execute_reply":"2023-12-02T15:34:24.209829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, in_channels, num_features):\n        super(CNN, self).__init__()\n\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels, 16, kernel_size=3),\n            nn.BatchNorm2d(16),\n            nn.ReLU())\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 16, kernel_size=3),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(16, 64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        \n        self.layer4 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n\n        self.fc = nn.Sequential(\n            nn.Linear(64 * 4 * 4, 128),\n            nn.ReLU(),\n            nn.Linear(128, num_features))\n\n\n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.212279Z","iopub.execute_input":"2023-12-02T15:34:24.212664Z","iopub.status.idle":"2023-12-02T15:34:24.223761Z","shell.execute_reply.started":"2023-12-02T15:34:24.212631Z","shell.execute_reply":"2023-12-02T15:34:24.22269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimCLR_Model(nn.Module):\n\n    def __init__(self, in_channels, n_features):\n        super(SimCLR_Model, self).__init__()\n        \n        self.n_features = n_features\n        \n        #CNN\n        self.cnn = CNN(in_channels, self.n_features)\n        \n\n        #The CNN already has an MLP built-in\n\n    def forward(self, x_i, x_j):\n        h_i = self.cnn(x_i)\n        h_j = self.cnn(x_j)\n\n        z_i, z_j = h_i, h_j \n        return z_i, z_j","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.226424Z","iopub.execute_input":"2023-12-02T15:34:24.226731Z","iopub.status.idle":"2023-12-02T15:34:24.233892Z","shell.execute_reply.started":"2023-12-02T15:34:24.226707Z","shell.execute_reply":"2023-12-02T15:34:24.233022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loss and train","metadata":{}},{"cell_type":"code","source":"class SimCLR_Loss(nn.Module):\n    def __init__(self, batch_size, temperature=1.0):\n        super().__init__()\n        self.batch_size = batch_size\n        self.temperature = temperature\n\n        self.mask = self.mask_correlated_samples(batch_size).to(device)\n        self.criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n        self.similarity_f = nn.CosineSimilarity(dim=2)\n\n    def mask_correlated_samples(self, batch_size):\n        N = 2 * batch_size\n        mask = torch.ones((N, N), dtype=bool)\n        mask = mask.fill_diagonal_(0)\n        \n        return mask\n\n    def forward(self, z_i, z_j):\n        N = 2 * self.batch_size\n        z = torch.cat((z_i, z_j), dim=0)\n        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0))\n        #sim[~self.mask] = float(\"-inf\")\n        \n        \n        \n        sim_i_j = torch.diag(sim, self.batch_size)\n        sim_j_i = torch.diag(sim, -self.batch_size)\n        \n        #Old implementation\n        '''positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)        \n        negative_samples = sim[self.mask].reshape(N, -1)\n         \n        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(device).long()\n        logits = torch.cat((positive_samples, negative_samples), dim=1)\n        \n        loss = self.criterion(logits, labels)\n        loss /= N'''\n        \n        #New implementation\n        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0)\n        numerator = torch.exp(positive_samples/self.temperature)\n        denominator = self.mask * torch.exp(sim / self.temperature)\n        all_losses = -torch.log(numerator / torch.sum(denominator, dim=1))\n        loss = torch.sum(all_losses) / N\n        \n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.235209Z","iopub.execute_input":"2023-12-02T15:34:24.235449Z","iopub.status.idle":"2023-12-02T15:34:24.249134Z","shell.execute_reply.started":"2023-12-02T15:34:24.235427Z","shell.execute_reply":"2023-12-02T15:34:24.248388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, optimizer, criterion, epoch):\n    \n    loss_epoch = 0\n    for step, ((x_i, x_j), label) in enumerate(train_loader):\n        optimizer.zero_grad()\n\n        x_i = x_i.to(device)\n        x_j = x_j.to(device)\n        \n        # positive pair, with encoding\n        z_i, z_j = model(x_i,x_j)\n\n        loss = criterion(z_i, z_j)\n        loss.backward()\n        \n\n        optimizer.step()\n\n        loss_epoch += loss.item()\n        \n        if step % (len(train_loader)//3) == 0:\n            print(f\"Epoch {epoch}[{step}/{len(train_loader)}] - Loss: {loss.item()}\")\n        \n    return loss_epoch","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.250292Z","iopub.execute_input":"2023-12-02T15:34:24.250751Z","iopub.status.idle":"2023-12-02T15:34:24.262779Z","shell.execute_reply.started":"2023-12-02T15:34:24.250695Z","shell.execute_reply":"2023-12-02T15:34:24.262017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_optimizer(optimizer_name, model, **kwargs):\n    if optimizer_name=='Adam':\n        optimizer = torch.optim.Adam(model.parameters(),lr=kwargs['lr'])\n    elif optimizer_name=='SGD':\n        optimizer = torch.optim.SGD(model.parameters(),lr=kwargs['lr'],momentum=kwargs['momentum'], weight_decay=kwargs['weight_decay'])\n    else:\n        raise ValueError('Not valid optimizer name')\n    return optimizer\n    \ndef make_scheduler(scheduler_name, optimizer, **kwargs):\n    if scheduler_name=='MultiStepLR':\n        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=kwargs['milestones'],gamma=kwargs['factor'])\n    elif scheduler_name=='CosineAnnealingLR':\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=kwargs['tmax'])\n    else:\n        raise ValueError('Not valid scheduler name')\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.263774Z","iopub.execute_input":"2023-12-02T15:34:24.264044Z","iopub.status.idle":"2023-12-02T15:34:24.27751Z","shell.execute_reply.started":"2023-12-02T15:34:24.264013Z","shell.execute_reply":"2023-12-02T15:34:24.276691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters and training","metadata":{}},{"cell_type":"code","source":"learning_rate = 0.001\noptimizer_name = 'Adam'\nscheduler_name = 'CosineAnnealingLR'\n\nmodel = SimCLR_Model(in_channels=n_channels, n_features=32).to(device)\ncriterion = SimCLR_Loss(batch_size=BATCH_SIZE, temperature=0.5).to(device)\noptimizer = make_optimizer(optimizer_name, model, lr=learning_rate)\n#scheduler = make_scheduler(scheduler_name, optimizer, milestones=[20], factor=0.1)\nscheduler = make_scheduler(scheduler_name, optimizer, tmax=num_epochs)\n\n\nfor epoch in range(1,num_epochs+1):\n    loss = train(model, train_loader, optimizer, criterion, epoch)\n    print(f'Epoch {epoch} - Loss: {loss}')\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:34:24.278404Z","iopub.execute_input":"2023-12-02T15:34:24.278767Z","iopub.status.idle":"2023-12-02T15:38:27.96659Z","shell.execute_reply.started":"2023-12-02T15:34:24.27874Z","shell.execute_reply":"2023-12-02T15:38:27.965571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Result","metadata":{}},{"cell_type":"code","source":"# linear evaluation\nfinetuning_size = int(0.1 * len(finetuning_set))\nfinetuning_indices = np.random.choice(len(finetuning_set), finetuning_size, replace=False)\nfinetuning_dataset = Subset(finetuning_set, finetuning_indices)\nfinetuning_dataloader = DataLoader(finetuning_dataset, batch_size=32, shuffle=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nclassifier = nn.Linear(model.n_features, n_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(classifier.parameters(), lr=0.001)\n\nfor epoch in range(num_epochs_finetune):\n    loss_epoch = 0\n    correct = 0\n    for inputs, labels in finetuning_dataloader:\n        # Forward pass through the classifier\n        inp = inputs.to(device)\n        labels = labels.to(device)\n        z_i, _ = model(inp, inp)\n        outputs = classifier(z_i)\n        pred = torch.argmax(outputs, dim=1)\n        \n\n        labels = labels.view(-1)\n        \n        \n        correct += (pred == labels).sum()\n        # Compute loss\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loss_epoch += loss.item()\n        \n    print(f'Epoch {epoch+1} - Loss: {loss_epoch} - Accuracy: {correct/finetuning_size}')","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:38:27.96772Z","iopub.execute_input":"2023-12-02T15:38:27.968021Z","iopub.status.idle":"2023-12-02T15:38:36.201494Z","shell.execute_reply.started":"2023-12-02T15:38:27.967994Z","shell.execute_reply":"2023-12-02T15:38:36.200509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\nfor inputs, labels in test_loader:\n    with torch.no_grad():\n            # Forward pass through the classifier\n            inp = inputs.to(device)\n            labels = labels.to(device)\n            z_i, _ = model(inp, inp)\n            outputs = classifier(z_i)\n            pred = torch.argmax(outputs, dim=1)\n\n\n            labels = labels.view(-1)\n\n\n            correct += (pred == labels).sum()\n\nprint(f'Test Accuracy: {correct/len(test_dataset)}')","metadata":{"execution":{"iopub.status.busy":"2023-12-02T15:38:36.202766Z","iopub.execute_input":"2023-12-02T15:38:36.203082Z","iopub.status.idle":"2023-12-02T15:38:37.861009Z","shell.execute_reply.started":"2023-12-02T15:38:36.203056Z","shell.execute_reply":"2023-12-02T15:38:37.860029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}