{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6uoVN0u3LB_"
   },
   "source": [
    "# The material presented in this notebook is for use in Introduction to Deep Learning ECE.685D course, Duke University, Fall 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRqGH8043LCB"
   },
   "source": [
    "* ### Static frameworks such as Theano, Caffe, and TensorFlow require the computational graph to be first declared, compiled, and then executed.\n",
    "* ### This leads to very efficient implementations (in production and mobile settings), it can become very painful during research and development. \n",
    "* ### Modern frameworks such as Chainer, DyNet, and PyTorch implement dynamic computational graphs. These are more flexible, and provide imperative style of coding.\n",
    "* ### We do not need to compile the models before every execution.\n",
    "* ### __PyTorch is a library (framework) which is optimized for tensor manipulation, and it provides a series of packages for deep learning.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtdCbJJZ3LCB"
   },
   "source": [
    "## __Modules and packages in Pytorch__\n",
    "* ### __torch :__  a Tensor library like Numpy, with strong GPU support\n",
    "* ### __torch.autograd :__ an automatic differentiation library that supports all differentiable Tensor operations in torch\n",
    "* ### __torch.nn :__ a neural networks library integrated with autograd\n",
    "* ### __torch.nn.functional :__ implementation of many useful mathematical functions such as Relu, Tanh, and so on.\n",
    "* ### __torch.optim :__ an optimization package to be used with torch.nn with standard optimization methods such as SGD, RMSProp, Adam, and so on.\n",
    "* ### __torch.utils :__ DataLoader, Trainer and other utility functions for convenience\n",
    "* ### __torchvision :__ Consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "* ### __torchaudio:__ Consists of I/O, popular datasets and common audio transformations (oading sound files in the wav and mp3 format). \n",
    "* ### __torchtext:__ Consists of  data processing utilities and popular datasets for natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxfPpa7i3LCB"
   },
   "source": [
    "## __Importing modules and packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mwtPedQx3LCC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XpdGrah3LCC"
   },
   "source": [
    "## __Diffferent level of abstractions__ \n",
    "* ### __Tensor:__ Like array in Numpy, but runs on a GPU to accelerate computing\n",
    "* ### __Module:__ A neural network layer --> storing states or learnable weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZZXVLVf3LCC"
   },
   "source": [
    "## __Getting started with Tensors__ \n",
    "https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WNQCdKb3LCD"
   },
   "source": [
    "## Constructing tensor directly using torch makes the data type as (default data type):\n",
    "* ### 32-bit floating point\n",
    "* ### torch.float32 or torch.float\n",
    "* ### torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tuh3HNd23LCD"
   },
   "source": [
    "## Construct a 10x3 matrix, uninitialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "quvHCmHF3LCE"
   },
   "outputs": [],
   "source": [
    "x = torch.empty(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiY1UgNj3LCE",
    "outputId": "1e9a6d44-b503-46b2-f9fa-54d2a1d318b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.8484e-08,  4.5664e-41, -4.7191e+27],\n",
       "        [ 4.5663e-41, -6.7662e-08,  4.5664e-41],\n",
       "        [-6.5862e-08,  4.5664e-41, -7.7374e-08],\n",
       "        [ 4.5664e-41, -7.6593e-08,  4.5664e-41],\n",
       "        [-3.0326e-08,  4.5664e-41, -7.4315e-08],\n",
       "        [ 4.5664e-41, -7.9082e-08,  4.5664e-41],\n",
       "        [-4.6956e+27,  4.5663e-41, -1.7355e-03],\n",
       "        [ 4.5663e-41, -6.6381e-08,  4.5664e-41],\n",
       "        [-1.7392e-03,  4.5663e-41, -7.9065e-08],\n",
       "        [ 4.5664e-41, -4.7175e+27,  4.5663e-41]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_v8XVgr3LCF"
   },
   "source": [
    "## Construct a a randomly (uniform distribution on the interval [0, 1]) initialized $5\\times 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RJj9Qmu73LCF"
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWIn-EWE3LCF",
    "outputId": "06368a1a-9634-4fdc-ef73-407b1bf010db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3912, 0.0060, 0.6137],\n",
       "        [0.6692, 0.0526, 0.4943],\n",
       "        [0.2612, 0.8139, 0.3615],\n",
       "        [0.5248, 0.0060, 0.2203],\n",
       "        [0.3428, 0.8901, 0.4727]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFDOGghg3LCG"
   },
   "source": [
    "## Construct a one matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0PW_OK-j3LCG"
   },
   "outputs": [],
   "source": [
    "x = torch.ones(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNQy_pgt3LCG",
    "outputId": "e3b5ce00-2db8-4958-d0f1-ee415a17e995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1xHw2Xi3LCG"
   },
   "source": [
    "## Construct a tensor from data (a 3-d tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nDiLTdrt3LCG"
   },
   "outputs": [],
   "source": [
    "y = torch.tensor([[[5.5, 3],[-3.8, 100]],[[1, 30],[023.8, 10]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61O2Orj63LCG"
   },
   "source": [
    "## The size or shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzxOw20R3LCG",
    "outputId": "03ac03d6-f1be-4007-8046-6477e58fd064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "****************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size())\n",
    "print('*'*40)\n",
    "x.shape  # shape built-in method in Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-x1whac3LCG"
   },
   "source": [
    "## Construct a tensor based on an existing tensor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv77JGQz3LCG"
   },
   "source": [
    "###  Creating a filled tensor \n",
    "* ### Any PyTorch method with an underscore (_) means an in-place operation (it modifies the content without creating a new object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nc3TUQUd3LCG",
    "outputId": "ad65ad60-ef58-4dc5-b4fc-a275cb752d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.],\n",
       "         [5.],\n",
       "         [5.]],\n",
       "\n",
       "        [[5.],\n",
       "         [5.],\n",
       "         [5.]],\n",
       "\n",
       "        [[5.],\n",
       "         [5.],\n",
       "         [5.]],\n",
       "\n",
       "        [[5.],\n",
       "         [5.],\n",
       "         [5.]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(4,3,1)\n",
    "x.fill_(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BViuQNEA3LCG"
   },
   "source": [
    "###  Reusing the properties of the input tensor, e.g. dtype, unless new values are provided by user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lulionR_vPwH",
    "outputId": "36f0ad9d-c746-4558-f027-85197042c5ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioiXkC7m3LCH",
    "outputId": "e4c4b9f2-1d3a-499b-b6db-9f34c7cd4ae2"
   },
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stPc6Q3K3LCH"
   },
   "source": [
    "### Changing the data type of a tensor in different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "DEjbjJ6D3LCH"
   },
   "outputs": [],
   "source": [
    "x = torch.ones(1,5)\n",
    "y = torch.randn_like(x) \n",
    "z = torch.randn_like(x, dtype=torch.double) \n",
    "t = y.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgHPM5D7v0nw",
    "outputId": "9c069178-0cbc-4abb-9430-8d75abe67d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([1, 5])\n",
      "Values: \n",
      "tensor([[ 1.9739,  1.0703, -1.7379,  0.1841, -0.1563]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "describe(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dO03uq_M3LCH",
    "outputId": "044031fd-2f34-4ae3-d5d1-2663fbddfc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 5])\n",
      "Values: \n",
      "tensor([[1., 1., 1., 1., 1.]])\n",
      "****************************************\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 5])\n",
      "Values: \n",
      "tensor([[-0.6681,  1.2135,  0.7924, -0.4401,  0.4996]])\n",
      "****************************************\n",
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([1, 5])\n",
      "Values: \n",
      "tensor([[-0.7581,  0.9989, -0.8793,  0.7486, -1.3375]], dtype=torch.float64)\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 5])\n",
      "Values: \n",
      "tensor([[0, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "describe(x)\n",
    "print('*'*40)\n",
    "describe(y)\n",
    "print('*'*40)\n",
    "describe(z)\n",
    "print('*'*40)\n",
    "describe(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6rqMCZ83LCH"
   },
   "source": [
    "# Getting started with Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIZX2Zbo3LCH"
   },
   "source": [
    "## Adding, subtracting,multiplying, deviding of two tensors (elementwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5FADkF83LCH",
    "outputId": "c5c873c5-69b4-46af-cbf2-3b808eea3c34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3270,  0.1976,  3.9246],\n",
      "        [ 0.2015,  0.4331,  0.9733],\n",
      "        [-0.5460, -1.1799,  1.2074],\n",
      "        [-0.9844,  0.8183,  1.4280],\n",
      "        [ 1.2545,  1.0662, -0.2704]])\n",
      "tensor([[ 1.3270, -0.8024,  2.9246],\n",
      "        [-0.7985, -0.5669, -0.0267],\n",
      "        [-1.5460, -2.1799,  0.2074],\n",
      "        [-1.9844, -0.1817,  0.4280],\n",
      "        [ 0.2545,  0.0662, -1.2704]])\n",
      "tensor([[ 1.3270, -0.8024,  2.9246],\n",
      "        [-0.7985, -0.5669, -0.0267],\n",
      "        [-1.5460, -2.1799,  0.2074],\n",
      "        [-1.9844, -0.1817,  0.4280],\n",
      "        [ 0.2545,  0.0662, -1.2704]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5,3)\n",
    "y = torch.ones(5,3)\n",
    "a = x + y\n",
    "print(a)\n",
    "b = x * y\n",
    "print(b)\n",
    "c = x/y\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3D5EoUw3LCH"
   },
   "source": [
    "## item() to get the value form a 0-rank tenser as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phrqARqQ3LCH",
    "outputId": "65e82229-a553-4200-fece-83cf68994ec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0637])\n",
      "0.06369499862194061\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJ2AWXdl3LCH"
   },
   "source": [
    "### Reshaping a torch tensor using __view__ (buit-in function in torch), or using __reshape__ (built-in method in Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfRVHhjC3LCH",
    "outputId": "fe32abc9-220b-48b5-d15e-069fa347d174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([10])\n",
      "Values: \n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([5, 2])\n",
      "Values: \n",
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5],\n",
      "        [6, 7],\n",
      "        [8, 9]])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([5, 2, 1, 1])\n",
      "Values: \n",
      "tensor([[[[0]],\n",
      "\n",
      "         [[1]]],\n",
      "\n",
      "\n",
      "        [[[2]],\n",
      "\n",
      "         [[3]]],\n",
      "\n",
      "\n",
      "        [[[4]],\n",
      "\n",
      "         [[5]]],\n",
      "\n",
      "\n",
      "        [[[6]],\n",
      "\n",
      "         [[7]]],\n",
      "\n",
      "\n",
      "        [[[8]],\n",
      "\n",
      "         [[9]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)   ## similar to \"range\" in python\n",
    "y = x.view(5,2)\n",
    "z = x.reshape(5,2,1,1)\n",
    "describe(x)\n",
    "print('*'*40)\n",
    "describe(y)\n",
    "print('*'*40)\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ena6MbRk3LCH"
   },
   "source": [
    "### Applying to a specific dimension of a tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQoB9CLa3LCI",
    "outputId": "4eab5838-982c-46b3-8eb8-d95405b47195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12)\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([7, 5])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([5, 7])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "12\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[3,2],[4,3]])\n",
    "print(torch.sum(x))\n",
    "print('*'*40)\n",
    "describe(torch.sum(x, dim=0))\n",
    "print('*'*40)\n",
    "describe(torch.sum(x, dim=1))\n",
    "print('*'*40)\n",
    "describe(torch.sum(x))\n",
    "print('*'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRpV_mNl3LCI"
   },
   "source": [
    "## Converting a Torch Tensor to a NumPy array and vice versa\n",
    "https://pytorch.org/docs/stable/notes/cuda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yApsdj3E3LCI"
   },
   "source": [
    "### From Tensor to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "y91Ff4E83LCI"
   },
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "x = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9LSPr2e3LCI",
    "outputId": "2b765fd9-e63a-45da-97a4-fdc77692708a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([5])\n",
      "Values: \n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "describe(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMS-gsQ53LCI"
   },
   "source": [
    "### preserving the data type after converting to the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0mGxgWA3LCI",
    "outputId": "b0d97f03-c54e-4b2a-bf72-c69d73f687ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsV452RL3LCI"
   },
   "source": [
    "### From Numpy to Tensor\n",
    "* ### Construcitng a tensor from a numpy array with float data type makes tensor data type as torch.DoubleTensor (float64)\n",
    "* ### Construcitng a tensor from a numpy array with integr data type makes tensor data type as torch.LongTensor (int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hs269zsk3LCI",
    "outputId": "d7f6fe30-1a25-4bf6-80dd-e8b17d229466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([5])\n",
      "Values: \n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "describe(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojA5zU3G3LCI"
   },
   "source": [
    "## Removing dimension with size 1 from a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMh-q_Ti3LCI",
    "outputId": "55b5cef0-14f3-4cb2-c29f-f1c88d8a3fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 2])\n",
      "torch.Size([5, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(5,1,2)\n",
    "print(a.size())\n",
    "b = torch.squeeze(a, dim=0)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvfjMnac3LCJ"
   },
   "source": [
    "## Expanding dimension a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9E8gu5n3LCJ",
    "outputId": "ac62c26c-6427-4892-e60e-85d40e9e08e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 1])\n",
      "torch.Size([5, 2, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(5,2,1)\n",
    "print(a.size())\n",
    "b = torch.unsqueeze(a, dim=2)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odYCr-xq3LCJ"
   },
   "source": [
    "## Indexing, Slicing, and Joining (very familiar to Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmrLNL5y3LCJ"
   },
   "source": [
    "* ### Simple indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nL4B5hAw3LCJ",
    "outputId": "f45a960a-bf71-4c7e-c8bb-6d4d1da667ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "0\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)\n",
    "print('*'*40)\n",
    "y = x[0, 0]\n",
    "describe(y)\n",
    "print('*'*40)\n",
    "z = x[1, 1]\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OevoRWki3LCJ"
   },
   "source": [
    "* ### Joining torch tensors using __torch.cat__ and __torch.stack__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGfjqNWy3LCJ",
    "outputId": "01bac80d-7837-4ac6-98bf-e2ec9e14e6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 6])\n",
      "Values: \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "****************************************\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2, 3])\n",
      "Values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2,3)\n",
    "describe(x)\n",
    "print('*'*40)\n",
    "describe(torch.cat((x,x), dim=1))\n",
    "print('*'*40)\n",
    "describe(torch.cat((x,x), dim=0))\n",
    "print('*'*40)\n",
    "describe(torch.stack((x, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUysgrU_060X",
    "outputId": "5d3a9e28-2f71-4a31-be71-ee0c19118530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSwVwFRv0nKV",
    "outputId": "5cd7a991-0875-431b-9917-9c0ce7a9f3d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAZxP4f33LCJ"
   },
   "source": [
    "## CUDA Tensors and GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIaYmm9g3LCJ"
   },
   "source": [
    "* ### Access to the GPUs is accomplished by an API called CUDA. \n",
    "* ### NVIDIA has created the CUDA API for only NVIDIA GPUs.\n",
    "* ### PyTorch offers CUDA tensor objects that are not different from the regular CPU-bound tensors except for end user.\n",
    "* ### Transfering Tensors to different devices, e.g., GPU, CPU using the __''.to''__ method.\n",
    "* ### To run on GPU, just cast tensors to a cuda data type!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nHJv65I3LCK"
   },
   "source": [
    "### First check if the CUDA interface exists on your system (__cuda.FloatTensor__ is a defualt data type for created toech tensors in GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Z8wiRyKc3LCK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    dtype = torch.cuda.FloatTensor         # casting tensors to a cuda data type\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrzLH8cr1XBU",
    "outputId": "8d180902-1e1e-4990-c0d1-1d08bc9c8576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_9npF6B3LCK"
   },
   "source": [
    "### Directly create a tensor on GPU, or use strings ``.to(\"cuda\")``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9qQahaqN3LCK"
   },
   "outputs": [],
   "source": [
    "b = torch.ones(3,4)\n",
    "y = torch.ones_like(b, device='cpu', dtype=torch.float)  \n",
    "x = torch.randn(y.size()).to('cuda') # or .to(y.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operation between tensors should on the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "wKQkUoQD3LCK",
    "outputId": "50d77c4f-156e-4aec-d334-e058ebc4666e"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(z)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IXyON7D3LCK"
   },
   "source": [
    "## AUTOGRAD: AUTOMATIC DIFFERENTIATION\n",
    "https://pytorch.org/docs/stable/autograd.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3IN8CDm3LCK"
   },
   "source": [
    "* ### Central to all neural networks in PyTorch is the autograd package.\n",
    "* ### Every Tensor has an attribute called __.requires_grad__ which can be True or False.\n",
    "* ### When it is True, starts to track all operations on it (bookkeeping).\n",
    "* ### When finishing the computation, one can call __.backward()__ and have all the gradients computed automatically\n",
    "* ### The gradient for the tensors will be accumulated into __.grad__ attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbjNGjC83LCK"
   },
   "source": [
    "### __To stop a tensor from tracking history:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfUexJKS3LCK"
   },
   "source": [
    "* ## First approach:\n",
    "###    - calling .detach() to detach it from the computation history\n",
    "###    - It also prevents future computation from being tracked\n",
    "\n",
    "* ## Second  approach:\n",
    "###   - wrap the code block using __with torch.no_grad()__ \n",
    "###   - Deactivating computation of the gradient for trainable parameters with __requires_grad=False__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am_wyFuo3LCK"
   },
   "source": [
    "## Each tensor has a .grad_fn attribute that references a Function that has created the Tensor \n",
    "(grad_fn is None for Tensors created by the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o3wAs5Wg3LCK",
    "outputId": "b32eef33-e90a-4cb9-ae74-fa6fc0ae69f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptkXp3K63LCK"
   },
   "source": [
    "### Operating a function on x makes the resulting tensor have __grad_fn__ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gi_oUZxT3LCK",
    "outputId": "0e4136d1-924f-409d-b335-a3a9fb5926e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rKDdXX83LCK"
   },
   "source": [
    "### __requires_grad_(.)__ changes an existing Tensor’s requires_grad flag in-place. \n",
    "### The input flag defaults to False if not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElekpnWU3LCK",
    "outputId": "bdbbd8dc-b092-4ca0-de3d-623ec4e2f757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float().view(2,2)\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZcqowua3LCK",
    "outputId": "454c37b7-56d3-4cb5-f2a8-4a0c300cb559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFl6eEfy3LCK",
    "outputId": "2c0378b9-a29e-4fbb-c781-e4d2bdd36cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x7f4ab12b5780>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y = (x * x).sum()\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlhA_x3M3LCK"
   },
   "source": [
    "### The backward pass is started by using the __backward()__ method \n",
    "###  __backward()__ method operates on a tensor resulting from the evaluation of a loss function. \n",
    "### The backward pass calculates a gradient value for a tensor object that involved in the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxHGpg3j3QHZ",
    "outputId": "b85b117a-8949-4b4e-991a-38fcf1d9052c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTi8rM1B3RSn",
    "outputId": "7bf3d01c-fcce-4164-cbf1-5dc850e82edb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [4., 9.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is needed in calculating the gradient?\n",
    "1. Input & output\n",
    "2. The intermediate values\n",
    "3. The Input-output mapping (e.g., computational graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djpwZRtF3LCL",
    "outputId": "1887516e-8242-4e0e-c993-acb14fe06807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "tensor([[0., 2.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "if x.grad is not None:\n",
    "    x.grad.zero_() # comment this line will accumulate gradients\n",
    "\n",
    "out = (x * x).sum()\n",
    "out2 = out + 3\n",
    "out2.backward()\n",
    "print(out)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward(): back propagate the gradient, and (defalut) clean the intermediate variables and computational graph. Unless the retain_graph option is stored as true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "x_grad = torch.autograd.grad(out,x)\n",
    "print(x_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 2.],\n",
      "        [4., 6.]]),)\n"
     ]
    }
   ],
   "source": [
    "out = (x * x).sum()\n",
    "out2 = out + 3\n",
    "x_grad = torch.autograd.grad(out,x)\n",
    "print(x_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9qvX0eL3LCL"
   },
   "source": [
    "### To explicitly compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3pxUvos3LCL",
    "outputId": "d9a8a75b-f921-48f3-a5fa-26d1f08fb794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  7.],\n",
      "        [12., 17.]], grad_fn=<AddBackward0>)\n",
      "(tensor([[ 20.,  70.],\n",
      "        [120., 170.]]),)\n"
     ]
    }
   ],
   "source": [
    "z = 5*x + 2\n",
    "print(z)\n",
    "out = (z* z).sum()\n",
    "x_grad = torch.autograd.grad(out,x)\n",
    "print(x_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do we need gradient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYyGbbqeg8PJ"
   },
   "source": [
    "# Why we need gradient? -- A Simple ML Model Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ZmJ2OuqLg-D7"
   },
   "outputs": [],
   "source": [
    "# define a \n",
    "x1 = torch.randn(1000)\n",
    "x2 = torch.randn(1000) * 2 + 15\n",
    "y = x1**2 + x2\n",
    "\n",
    "data = torch.stack((x1,x2),dim=1)\n",
    "target = y\n",
    "train_data = torch.cat((data,target.unsqueeze(1)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fT34mzcLjquG",
    "outputId": "f850a3f3-f239-40ea-f283-870da1b414cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "DBk1DFuOhUWP"
   },
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, hidden_dim=3):\n",
    "    '''\n",
    "    input_dim, output_dim:self-evident; \n",
    "    hidden_dim: all neural networks in this model are using the same hidden layer dimension for simplicity \n",
    "    '''\n",
    "    super().__init__()\n",
    "    \n",
    "    neuralnet = [nn.Linear(input_dim,hidden_dim),nn.ELU(),nn.Linear(hidden_dim, output_dim)]\n",
    "    self.neuralnet = nn.Sequential(*neuralnet)\n",
    "\n",
    "    \n",
    "  def forward(self,X):\n",
    "\n",
    "    y = self.neuralnet(X)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "zYR1Lri8iSP0"
   },
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss as MSE\n",
    "mse = MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_prEZTaYiVXy",
    "outputId": "a785e2d8-792f-4f2d-c608-782c9fbc1bd1"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "#define a dataloader\n",
    "loader = DataLoader(train_data,batch_size=100, shuffle=True)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = net(input_dim=2, output_dim=1)\n",
    "EPOCHS = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "MSE = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/50 [00:09<?, ?it/s]\u001b[A\n",
      "/home/ziyun/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\n",
      " 24%|██████████                                | 12/50 [00:00<00:00, 113.87it/s]\u001b[A\n",
      " 48%|████████████████████▏                     | 24/50 [00:00<00:00, 114.62it/s]\u001b[A\n",
      " 72%|██████████████████████████████▏           | 36/50 [00:00<00:00, 114.09it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 112.37it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "tqdm_epoch = tqdm.trange(EPOCHS)\n",
    "for _ in tqdm_epoch:\n",
    "  for tr in loader:  \n",
    "    X = tr[:,0:2] # data\n",
    "    y = tr[:,2] # target\n",
    "    optimizer.zero_grad()  \n",
    "    y_est = model(X)\n",
    "    loss =  mse(y_est,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  MSE.append(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "QidCQoI4icoA",
    "outputId": "e77de688-55d4-40f1-b291-2b664a4e5b8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b8c1ee9b0>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_N0D3jpkN6M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
